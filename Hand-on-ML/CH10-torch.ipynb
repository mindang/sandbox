{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fashion_mnist데이터로 MLP구현 \\<Torch>\n",
    "- nn.NLLLoss() 와 nn.CrossEntropyLoss()의 차이\n",
    "- torch.nn.CrossEntropyLoss는 softmax + NLLLoss이다.\n",
    "    - 즉 , 모델의 출력층에 softmax()가 없는 모델에 사용해야한다.\n",
    "- 만약 지금처럼 model의 출력층에 softmax()가 있다면 NLLLoss()를 사용해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# 데이터셋 적재\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full , y_train_full) , (X_test , y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# 정규화 값을 0 ~ 1사이로 맞추기\n",
    "X_valid , X_train = X_train_full[:5000]/255.0 , X_train_full[5000:]/255.0\n",
    "y_valid , y_train = y_train_full[:5000] , y_train_full[5000:]\n",
    "X_test = X_test/255.0\n",
    "\n",
    "# 클래스 이름 리스트 정의\n",
    "class_names = [\"T-shirt\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle Boot\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두개의 은닉층으로 이루어진 MLP\n",
    "    - 텐서플로의 Dense는 토치의 Linear와 동일\n",
    "        - 단 Dense의 use_bias=True (default임)가 옵션이지만 Linear은 bias가 포함되어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "이 방법은 계산 그래프를 생성하지 않고 순전파에서 모든 계산을 수행함\n",
    "따라서 파이토치의 자동미분 backward()를 수행할 때 참고할 계산 그래프가 없으므로 backward()를 사용할 수 없다.\n",
    "따라서 이방법은 사용하지 않는다!\n",
    "즉 , forward()에서 필요한 layer들은 미리 __init__에 선언해놓자!!!!!\n",
    "class Mlp_Net(nn.module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Mlp_Net,self).__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = nn.ReLU(nn.Linear(28*28,300)(x.view(-1,28*28)))\n",
    "        x = nn.ReLU(nn.Linear(300,100)(x))\n",
    "        x = nn.Softmax(x,dim=1)\n",
    "        return x\n",
    "'''\n",
    "class Mlp_Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Mlp_Net,self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layer1 = nn.Linear(28*28,300) # 입력 -> 출력 차원\n",
    "        self.layer2 = nn.Linear(300,100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mlp_Net(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layer1): Linear(in_features=784, out_features=300, bias=True)\n",
      "  (layer2): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.kaiming_uniform_(m.weight.data)\n",
    "\n",
    "model = Mlp_Net()\n",
    "model.apply(weight_init)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.weight torch.Size([300, 784])\n",
      "layer1.bias torch.Size([300])\n",
      "layer2.weight torch.Size([100, 300])\n",
      "layer2.bias torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for name , param in model.named_parameters():\n",
    "    print(name , param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300, 784]) torch.Size([100])\n",
      "tensor(-0.0080, grad_fn=<SelectBackward0>)\n",
      "tensor(0., grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 파라미터에 직접 접근하기\n",
    "# 그래프에 직접 접근은 지양해야하며 .data로 접근할 수 있다.\n",
    "'''\n",
    "print(model.layer1.weight.shape,model.layer2.bias.shape)\n",
    "print(model.layer1.weight[0,0])\n",
    "model.layer1.weight.data[0,0] = 0\n",
    "print(model.layer1.weight[0,0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_32920\\3716671605.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train , y_train = torch.tensor(X_train,dtype=torch.float32,requires_grad=False) , torch.tensor(y_train,requires_grad=False)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_32920\\3716671605.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_valid , y_valid = torch.tensor(X_valid,dtype=torch.float32,requires_grad=False) , torch.tensor(y_valid,requires_grad=False)\n"
     ]
    }
   ],
   "source": [
    "# 데이터로더\n",
    "batch_size = 32\n",
    "X_train , y_train = torch.tensor(X_train,dtype=torch.float32,requires_grad=False) , torch.tensor(y_train,requires_grad=False)\n",
    "X_valid , y_valid = torch.tensor(X_valid,dtype=torch.float32,requires_grad=False) , torch.tensor(y_valid,requires_grad=False)\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(TensorDataset(X_valid, y_valid), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "from tqdm import tqdm\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "def acc(x,y):\n",
    "    cnt = 0\n",
    "    for a,b in zip(x,y):\n",
    "        if a==b:\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image\n",
    "        label = label\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad(): # 파라미터 업데이트 방지\n",
    "        for image, label in test_loader:\n",
    "            image = image\n",
    "            label = label\n",
    "            output = model(image)\n",
    "            test_loss += loss_fn(output, label).item()\n",
    "            prediction = output.max(1, keepdim=True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH: 1], \tTest Loss: 0.1362, \tTest Accuracy: 28.68 %\n",
      "[EPOCH: 2], \tTest Loss: 0.1337, \tTest Accuracy: 38.14 %\n",
      "[EPOCH: 3], \tTest Loss: 0.1334, \tTest Accuracy: 38.22 %\n",
      "[EPOCH: 4], \tTest Loss: 0.1334, \tTest Accuracy: 38.26 %\n",
      "[EPOCH: 5], \tTest Loss: 0.1332, \tTest Accuracy: 38.36 %\n",
      "[EPOCH: 6], \tTest Loss: 0.1332, \tTest Accuracy: 38.48 %\n",
      "[EPOCH: 7], \tTest Loss: 0.1332, \tTest Accuracy: 38.44 %\n",
      "[EPOCH: 8], \tTest Loss: 0.1332, \tTest Accuracy: 38.50 %\n",
      "[EPOCH: 9], \tTest Loss: 0.1331, \tTest Accuracy: 38.62 %\n",
      "[EPOCH: 10], \tTest Loss: 0.1331, \tTest Accuracy: 38.48 %\n",
      "[EPOCH: 11], \tTest Loss: 0.1331, \tTest Accuracy: 38.68 %\n",
      "[EPOCH: 12], \tTest Loss: 0.1331, \tTest Accuracy: 38.70 %\n",
      "[EPOCH: 13], \tTest Loss: 0.1331, \tTest Accuracy: 38.60 %\n",
      "[EPOCH: 14], \tTest Loss: 0.1331, \tTest Accuracy: 38.56 %\n",
      "[EPOCH: 15], \tTest Loss: 0.1331, \tTest Accuracy: 38.52 %\n",
      "[EPOCH: 16], \tTest Loss: 0.1331, \tTest Accuracy: 38.60 %\n",
      "[EPOCH: 17], \tTest Loss: 0.1330, \tTest Accuracy: 38.90 %\n",
      "[EPOCH: 18], \tTest Loss: 0.1331, \tTest Accuracy: 38.64 %\n",
      "[EPOCH: 19], \tTest Loss: 0.1330, \tTest Accuracy: 38.76 %\n",
      "[EPOCH: 20], \tTest Loss: 0.1331, \tTest Accuracy: 38.70 %\n",
      "[EPOCH: 21], \tTest Loss: 0.1331, \tTest Accuracy: 38.72 %\n",
      "[EPOCH: 22], \tTest Loss: 0.1331, \tTest Accuracy: 38.54 %\n",
      "[EPOCH: 23], \tTest Loss: 0.1331, \tTest Accuracy: 38.78 %\n",
      "[EPOCH: 24], \tTest Loss: 0.1330, \tTest Accuracy: 38.92 %\n",
      "[EPOCH: 25], \tTest Loss: 0.1330, \tTest Accuracy: 38.78 %\n",
      "[EPOCH: 26], \tTest Loss: 0.1330, \tTest Accuracy: 38.84 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m epoch \u001b[39m=\u001b[39m \u001b[39m40\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m Epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     train(model, train_loader, optimizer, log_interval\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m     test_loss, test_accuracy \u001b[39m=\u001b[39m evaluate(model, valid_loader)\n\u001b[0;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[EPOCH: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m], \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mTest Loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mTest Accuracy: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m      7\u001b[0m         Epoch, test_loss, test_accuracy\n\u001b[0;32m      8\u001b[0m     ))\n",
      "Cell \u001b[1;32mIn[30], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, log_interval)\u001b[0m\n\u001b[0;32m     19\u001b[0m output \u001b[39m=\u001b[39m model(image)\n\u001b[0;32m     20\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(output, label)\n\u001b[1;32m---> 21\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     22\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\kdt_venv\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\kdt_venv\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "epoch = 40\n",
    "for Epoch in range(1, epoch + 1):\n",
    "    train(model, train_loader, optimizer, log_interval=100)\n",
    "    test_loss, test_accuracy = evaluate(model, valid_loader)\n",
    "    print(\"[EPOCH: {}], \\tValid Loss: {:.4f}, \\tValid Accuracy: {:.2f} %\".format(\n",
    "        Epoch, test_loss, test_accuracy\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: -0.37929072535318853\n",
      "Training loss: -0.3793148089973922\n",
      "Training loss: -0.3793513963585194\n",
      "Training loss: -0.3793505176060972\n",
      "Training loss: -0.37938417107681677\n",
      "Training loss: -0.3794169863463835\n",
      "Training loss: -0.37938999119385375\n",
      "Training loss: -0.37939091448072365\n",
      "Training loss: -0.37943798652944905\n",
      "Training loss: -0.379438490347331\n",
      "Training loss: -0.3794707592756614\n",
      "Training loss: -0.3794746707871322\n",
      "Training loss: -0.37951438854502134\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m loss \u001b[39m=\u001b[39m criterion(output,labels)\n\u001b[0;32m     19\u001b[0m \u001b[39m#backward pass calculate the gradients for loss\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     22\u001b[0m \u001b[39m# update the parameters\u001b[39;00m\n\u001b[0;32m     23\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\kdt_venv\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\kdt_venv\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs =30\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.001)\n",
    "for e in range(epochs):\n",
    "  running_loss = 0\n",
    "  for images, labels in train_loader:\n",
    "    \n",
    "    #Flatten the image into a 784 long vector\n",
    "    \n",
    "    images = images.view(images.shape[0],-1) #sqash the image in to 784*1 vector\n",
    "    \n",
    "    #reset the default gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # forward pass\n",
    "    output = model(images)\n",
    "    loss = criterion(output,labels)\n",
    "    \n",
    "    #backward pass calculate the gradients for loss\n",
    "    loss.backward()\n",
    "    \n",
    "    # update the parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    running_loss = running_loss+loss.item()\n",
    "  else:\n",
    "    print(f\"Training loss: {running_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 안되서 긁어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [01:23<00:00, 316014.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 101044.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:11<00:00, 378168.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 5153288.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "#transforms.ToTensor() convert our image to a tensor\n",
    "#transforms.Normalize() will normalizae our image with provided mean and sd values\n",
    "\n",
    "# Download and load training data\n",
    "\n",
    "trainset = datasets.FashionMNIST('./data',download=True, train= True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size= 64, shuffle=True)\n",
    "\n",
    "# Download and load test data\n",
    "testset = datasets.FashionMNIST('./data',download=True, train= False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size= 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network parameters\n",
    "\n",
    "input_size = 784 #i.e 28*28*1 \n",
    "hidden_size = [300,100]\n",
    "out_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import NLLLoss\n",
    "from torch.optim import SGD\n",
    "\n",
    "model = nn.Sequential(\n",
    "nn.Flatten(),\n",
    "nn.Linear(input_size,hidden_size[0]),\n",
    "nn.ReLU(),\n",
    "nn.Linear(hidden_size[0],hidden_size[1]),\n",
    "nn.ReLU(),\n",
    "nn.Linear(hidden_size[1],out_size),\n",
    "nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "criterion = NLLLoss()\n",
    "optimizer = SGD(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=300, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (6): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.264903717966222\n",
      "Training loss: 2.1395309641162976\n",
      "Training loss: 1.8974709959426668\n",
      "Training loss: 1.581385413593829\n",
      "Training loss: 1.3329489269236257\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      4\u001b[0m   running_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m----> 5\u001b[0m   \u001b[39mfor\u001b[39;00m images, labels \u001b[39min\u001b[39;00m trainloader:\n\u001b[0;32m      6\u001b[0m     \n\u001b[0;32m      7\u001b[0m     \u001b[39m#Flatten the image into a 784 long vector\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \n\u001b[0;32m      9\u001b[0m     \u001b[39m#images = images.view(images.shape[0],-1) #sqash the image in to 784*1 vector\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \n\u001b[0;32m     11\u001b[0m     \u001b[39m#reset the default gradients\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     14\u001b[0m     \u001b[39m# forward pass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\kdt_venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\kdt_venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\kdt_venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\kdt_venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\kdt_venv\\lib\\site-packages\\torchvision\\datasets\\mnist.py:138\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Any, Any]:\n\u001b[0;32m    131\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m        index (int): Index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     img, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[index], \u001b[39mint\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtargets[index])\n\u001b[0;32m    140\u001b[0m     \u001b[39m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[39m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs =30\n",
    "\n",
    "for e in range(epochs):\n",
    "  running_loss = 0\n",
    "  for images, labels in trainloader:\n",
    "    \n",
    "    #Flatten the image into a 784 long vector\n",
    "    \n",
    "    #images = images.view(images.shape[0],-1) #sqash the image in to 784*1 vector\n",
    "    \n",
    "    #reset the default gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # forward pass\n",
    "    output = model(images)\n",
    "    loss = criterion(output,labels)\n",
    "    \n",
    "    #backward pass calculate the gradients for loss\n",
    "    loss.backward()\n",
    "    \n",
    "    # update the parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    running_loss = running_loss+loss.item()\n",
    "  else:\n",
    "    print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
