{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fashion_mnist데이터로 MLP구현 \\<Torch>\n",
    "- nn.NLLLoss() 와 nn.CrossEntropyLoss()의 차이\n",
    "- torch.nn.CrossEntropyLoss는 softmax + NLLLoss이다.\n",
    "    - 즉 , 모델의 출력층에 softmax()가 없는 모델에 사용해야한다.\n",
    "- 만약 지금처럼 model의 출력층에 LogSoftmax()가 있다면 NLLLoss()를 사용해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# 데이터셋 적재\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full , y_train_full) , (X_test , y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# 정규화 값을 0 ~ 1사이로 맞추기\n",
    "X_valid , X_train = X_train_full[:5000]/255.0 , X_train_full[5000:]/255.0\n",
    "y_valid , y_train = y_train_full[:5000] , y_train_full[5000:]\n",
    "X_test = X_test/255.0\n",
    "\n",
    "X_valid , X_train = torch.tensor(X_valid,dtype=torch.float32) , torch.tensor(X_train,dtype=torch.float32)\n",
    "y_valid , y_train = torch.tensor(y_valid) , torch.tensor(y_train)\n",
    "X_test , y_test = torch.tensor(X_test,dtype=torch.float32) , torch.tensor(y_test)\n",
    "\n",
    "# 클래스 이름 리스트 정의\n",
    "class_names = [\"T-shirt\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle Boot\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두개의 은닉층으로 이루어진 MLP\n",
    "    - 텐서플로의 Dense는 토치의 Linear와 동일\n",
    "        - 단 Dense의 use_bias=True (default임)가 옵션이지만 Linear은 bias가 포함되어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "이 방법은 계산 그래프를 생성하지 않고 순전파에서 모든 계산을 수행함\n",
    "따라서 파이토치의 자동미분 backward()를 수행할 때 참고할 계산 그래프가 없으므로 backward()를 사용할 수 없다.\n",
    "따라서 이방법은 사용하지 않는다!\n",
    "즉 , forward()에서 필요한 layer들은 미리 __init__에 선언해놓자!!!!!\n",
    "class Mlp_Net(nn.module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Mlp_Net,self).__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = nn.ReLU(nn.Linear(28*28,300)(x.view(-1,28*28)))\n",
    "        x = nn.ReLU(nn.Linear(300,100)(x))\n",
    "        x = nn.Softmax(x,dim=1)\n",
    "        return x\n",
    "'''\n",
    "class Mlp_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layer1 = nn.Linear(28*28,300) # 입력 -> 출력 차원\n",
    "        self.layer2 = nn.Linear(300,100)\n",
    "        self.layer3 = nn.Linear(100,10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mlp_Net(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layer1): Linear(in_features=784, out_features=300, bias=True)\n",
      "  (layer2): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (layer3): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Mlp_Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.weight torch.Size([300, 784]) torch.float32\n",
      "layer1.bias torch.Size([300]) torch.float32\n",
      "layer2.weight torch.Size([100, 300]) torch.float32\n",
      "layer2.bias torch.Size([100]) torch.float32\n",
      "layer3.weight torch.Size([10, 100]) torch.float32\n",
      "layer3.bias torch.Size([10]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "for name , param in model.named_parameters():\n",
    "    print(name , param.shape,param.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(model.layer1.weight.shape,model.layer2.bias.shape)\\nprint(model.layer1.weight[0,0])\\nmodel.layer1.weight.data[0,0] = 0\\nprint(model.layer1.weight[0,0])\\n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파라미터에 직접 접근하기\n",
    "# 그래프에 직접 접근은 지양해야하며 .data로 접근할 수 있다.\n",
    "'''\n",
    "print(model.layer1.weight.shape,model.layer2.bias.shape)\n",
    "print(model.layer1.weight[0,0])\n",
    "model.layer1.weight.data[0,0] = 0\n",
    "print(model.layer1.weight[0,0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로더\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(TensorDataset(X_valid, y_valid), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "def acc(x,y):\n",
    "    cnt = 0\n",
    "    for a,b in zip(x,y):\n",
    "        if a==b:\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def train(model, train_loader, optimizer, metric):\n",
    "    model.train()\n",
    "    for image, label in train_loader:\n",
    "        output = model(image)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad(): # 파라미터 업데이트 방지\n",
    "        for image, label in test_loader:\n",
    "            image = image\n",
    "            label = label\n",
    "            output = model(image)\n",
    "            test_loss += loss_fn(output, label).item()\n",
    "            prediction = output.max(1, keepdim=True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/41 [00:02<01:49,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.003747050677239895 val_acc : 41.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 2/41 [00:05<01:43,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.012005953964591027 val_acc : 47.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3/41 [00:07<01:40,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.014598639488220214 val_acc : 47.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4/41 [00:10<01:37,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.015745650386810302 val_acc : 53.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 5/41 [00:13<01:34,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.016642165166139603 val_acc : 55.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 6/41 [00:15<01:31,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017077452802658082 val_acc : 56.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 7/41 [00:18<01:28,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017341858434677122 val_acc : 56.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 8/41 [00:20<01:26,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017465568751096724 val_acc : 56.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 9/41 [00:23<01:23,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017554527819156646 val_acc : 56.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 10/41 [00:26<01:20,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.01765144989490509 val_acc : 56.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 11/41 [00:28<01:18,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.01766821229457855 val_acc : 56.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 12/41 [00:31<01:15,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017724383062124253 val_acc : 57.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 13/41 [00:34<01:12,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.01776611030101776 val_acc : 57.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 14/41 [00:36<01:10,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017812043064832687 val_acc : 57.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 15/41 [00:39<01:08,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.01779782167673111 val_acc : 57.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 16/41 [00:41<01:05,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017866564816236497 val_acc : 57.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 17/41 [00:44<01:02,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017849369859695433 val_acc : 57.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 18/41 [00:47<01:00,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.01787747374176979 val_acc : 57.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 19/41 [00:49<00:57,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017893722343444825 val_acc : 57.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 20/41 [00:52<00:55,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.01797194255590439 val_acc : 57.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 21/41 [00:55<00:52,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.01795368294119835 val_acc : 57.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 22/41 [00:57<00:49,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017927207136154175 val_acc : 57.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 23/41 [01:00<00:47,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017922727411985397 val_acc : 57.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 24/41 [01:02<00:44,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017957025736570358 val_acc : 57.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 25/41 [01:05<00:41,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017962166011333467 val_acc : 57.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 26/41 [01:08<00:39,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017932823574543 val_acc : 57.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 27/41 [01:10<00:36,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017999548971652984 val_acc : 57.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 28/41 [01:13<00:34,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017942177510261535 val_acc : 57.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 29/41 [01:16<00:31,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.018008049458265306 val_acc : 57.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 30/41 [01:18<00:28,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017985673123598098 val_acc : 57.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 31/41 [01:21<00:26,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017996062034368515 val_acc : 57.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 32/41 [01:23<00:23,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.018017191165685655 val_acc : 57.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 33/41 [01:26<00:20,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017982900536060335 val_acc : 57.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 34/41 [01:29<00:18,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017995930689573288 val_acc : 57.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 35/41 [01:31<00:15,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017996872216463088 val_acc : 57.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 36/41 [01:34<00:13,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.01798123550415039 val_acc : 57.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 37/41 [01:37<00:10,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.018054481214284896 val_acc : 57.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 38/41 [01:39<00:07,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.018039374619722368 val_acc : 57.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 39/41 [01:42<00:05,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017999202811717987 val_acc : 57.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 40/41 [01:45<00:02,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.01800446752309799 val_acc : 57.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [01:47<00:00,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 40 val_loss : -0.017981407716870308 val_acc : 57.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "from tqdm import tqdm\n",
    "\n",
    "epoch = 40\n",
    "for Epoch in tqdm(range(1+epoch)):\n",
    "    train(model, train_loader, optimizer, acc)\n",
    "    test_loss, test_accuracy = evaluate(model, valid_loader)\n",
    "    print(f'epoch : {epoch} val_loss : {test_loss} val_acc : {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: -0.37929072535318853\n",
      "Training loss: -0.3793148089973922\n",
      "Training loss: -0.3793513963585194\n",
      "Training loss: -0.3793505176060972\n",
      "Training loss: -0.37938417107681677\n",
      "Training loss: -0.3794169863463835\n",
      "Training loss: -0.37938999119385375\n",
      "Training loss: -0.37939091448072365\n",
      "Training loss: -0.37943798652944905\n",
      "Training loss: -0.379438490347331\n",
      "Training loss: -0.3794707592756614\n",
      "Training loss: -0.3794746707871322\n",
      "Training loss: -0.37951438854502134\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m loss \u001b[39m=\u001b[39m criterion(output,labels)\n\u001b[0;32m     19\u001b[0m \u001b[39m#backward pass calculate the gradients for loss\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     22\u001b[0m \u001b[39m# update the parameters\u001b[39;00m\n\u001b[0;32m     23\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\kdt_venv\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\miniconda3\\envs\\kdt_venv\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs =30\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.001)\n",
    "for e in range(epochs):\n",
    "  running_loss = 0\n",
    "  for images, labels in train_loader:\n",
    "    \n",
    "    #Flatten the image into a 784 long vector\n",
    "    \n",
    "    images = images.view(images.shape[0],-1) #sqash the image in to 784*1 vector\n",
    "    \n",
    "    #reset the default gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # forward pass\n",
    "    output = model(images)\n",
    "    loss = criterion(output,labels)\n",
    "    \n",
    "    #backward pass calculate the gradients for loss\n",
    "    loss.backward()\n",
    "    \n",
    "    # update the parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    running_loss = running_loss+loss.item()\n",
    "  else:\n",
    "    print(f\"Training loss: {running_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 안되서 긁어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = datasets.FashionMNIST('./data',download=True, train= True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size= 64, shuffle=True)\n",
    "\n",
    "# Download and load test data\n",
    "testset = datasets.FashionMNIST('./data',download=True, train= False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size= 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import NLLLoss\n",
    "from torch.optim import SGD\n",
    "\n",
    "model = nn.Sequential(\n",
    "nn.Flatten(),\n",
    "nn.Linear(28*28,300),\n",
    "nn.ReLU(),\n",
    "nn.Linear(300,100),\n",
    "nn.ReLU(),\n",
    "nn.Linear(100,10)\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=300, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1epoch Train_loss: 1.43 Train_acc: 53.69%|Test_loss: 0.85 Test_acc: 68.56%\n",
      "2epoch Train_loss: 0.73 Train_acc: 73.69%|Test_loss: 0.67 Test_acc: 76.39%\n",
      "3epoch Train_loss: 0.60 Train_acc: 78.79%|Test_loss: 0.59 Test_acc: 79.46%\n",
      "4epoch Train_loss: 0.54 Train_acc: 81.26%|Test_loss: 0.54 Test_acc: 80.93%\n",
      "5epoch Train_loss: 0.50 Train_acc: 82.52%|Test_loss: 0.51 Test_acc: 81.92%\n",
      "6epoch Train_loss: 0.48 Train_acc: 83.22%|Test_loss: 0.52 Test_acc: 80.41%\n",
      "7epoch Train_loss: 0.46 Train_acc: 83.81%|Test_loss: 0.48 Test_acc: 83.08%\n",
      "8epoch Train_loss: 0.45 Train_acc: 84.35%|Test_loss: 0.48 Test_acc: 83.07%\n",
      "9epoch Train_loss: 0.43 Train_acc: 84.82%|Test_loss: 0.47 Test_acc: 83.51%\n",
      "10epoch Train_loss: 0.42 Train_acc: 85.24%|Test_loss: 0.46 Test_acc: 83.57%\n",
      "11epoch Train_loss: 0.42 Train_acc: 85.58%|Test_loss: 0.45 Test_acc: 83.92%\n",
      "12epoch Train_loss: 0.41 Train_acc: 85.75%|Test_loss: 0.47 Test_acc: 83.72%\n",
      "13epoch Train_loss: 0.40 Train_acc: 86.11%|Test_loss: 0.44 Test_acc: 84.33%\n",
      "14epoch Train_loss: 0.39 Train_acc: 86.29%|Test_loss: 0.43 Test_acc: 84.71%\n",
      "15epoch Train_loss: 0.39 Train_acc: 86.59%|Test_loss: 0.42 Test_acc: 84.93%\n",
      "16epoch Train_loss: 0.38 Train_acc: 86.54%|Test_loss: 0.42 Test_acc: 85.25%\n",
      "17epoch Train_loss: 0.38 Train_acc: 86.79%|Test_loss: 0.42 Test_acc: 85.34%\n",
      "18epoch Train_loss: 0.37 Train_acc: 87.12%|Test_loss: 0.41 Test_acc: 85.38%\n",
      "19epoch Train_loss: 0.36 Train_acc: 87.14%|Test_loss: 0.41 Test_acc: 85.70%\n",
      "20epoch Train_loss: 0.36 Train_acc: 87.28%|Test_loss: 0.40 Test_acc: 86.06%\n",
      "21epoch Train_loss: 0.36 Train_acc: 87.39%|Test_loss: 0.41 Test_acc: 85.57%\n",
      "22epoch Train_loss: 0.35 Train_acc: 87.70%|Test_loss: 0.39 Test_acc: 86.27%\n",
      "23epoch Train_loss: 0.34 Train_acc: 87.85%|Test_loss: 0.40 Test_acc: 85.54%\n",
      "24epoch Train_loss: 0.34 Train_acc: 87.91%|Test_loss: 0.40 Test_acc: 85.48%\n",
      "25epoch Train_loss: 0.34 Train_acc: 88.11%|Test_loss: 0.39 Test_acc: 86.26%\n",
      "26epoch Train_loss: 0.33 Train_acc: 88.27%|Test_loss: 0.38 Test_acc: 86.37%\n",
      "27epoch Train_loss: 0.33 Train_acc: 88.29%|Test_loss: 0.38 Test_acc: 86.47%\n",
      "28epoch Train_loss: 0.33 Train_acc: 88.47%|Test_loss: 0.38 Test_acc: 86.49%\n",
      "29epoch Train_loss: 0.32 Train_acc: 88.57%|Test_loss: 0.37 Test_acc: 86.88%\n",
      "30epoch Train_loss: 0.32 Train_acc: 88.69%|Test_loss: 0.38 Test_acc: 86.54%\n",
      "31epoch Train_loss: 0.31 Train_acc: 88.82%|Test_loss: 0.40 Test_acc: 85.52%\n",
      "32epoch Train_loss: 0.31 Train_acc: 88.88%|Test_loss: 0.37 Test_acc: 86.72%\n",
      "33epoch Train_loss: 0.31 Train_acc: 89.01%|Test_loss: 0.37 Test_acc: 86.92%\n",
      "34epoch Train_loss: 0.30 Train_acc: 89.21%|Test_loss: 0.36 Test_acc: 87.17%\n",
      "35epoch Train_loss: 0.30 Train_acc: 89.23%|Test_loss: 0.39 Test_acc: 85.77%\n",
      "36epoch Train_loss: 0.30 Train_acc: 89.36%|Test_loss: 0.36 Test_acc: 87.28%\n",
      "37epoch Train_loss: 0.29 Train_acc: 89.50%|Test_loss: 0.37 Test_acc: 86.77%\n",
      "38epoch Train_loss: 0.29 Train_acc: 89.64%|Test_loss: 0.43 Test_acc: 85.70%\n",
      "39epoch Train_loss: 0.29 Train_acc: 89.69%|Test_loss: 0.36 Test_acc: 87.32%\n",
      "40epoch Train_loss: 0.28 Train_acc: 89.88%|Test_loss: 0.37 Test_acc: 86.85%\n"
     ]
    }
   ],
   "source": [
    "epochs =40\n",
    "\n",
    "for e in range(epochs):\n",
    "  total_loss , total_acc ,tot = 0 , 0 ,0\n",
    "  for images, labels in trainloader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    output = model(images)\n",
    "    loss = criterion(output,labels)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    pred = torch.max(output, 1)[1].to(device)\n",
    "    total_loss += loss.item() * len(labels)\n",
    "    total_acc += (pred == labels).sum()\n",
    "  else:\n",
    "    print(f\"{e+1}epoch Train_loss: {total_loss/len(trainloader.dataset):.2f} Train_acc: {100*total_acc/len(trainloader.dataset):.2f}%\",end='|')\n",
    "\n",
    "\n",
    "  total_loss , total_acc = 0 , 0\n",
    "  with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      output = model(images)\n",
    "      loss = criterion(output,labels)\n",
    "\n",
    "      pred = torch.max(output, 1)[1].to(device)\n",
    "      total_loss += loss.item() * len(labels)\n",
    "      total_acc += (pred == labels).sum()\n",
    "    else:\n",
    "      print(f\"Test_loss: {total_loss/len(testloader.dataset):.2f} Test_acc: {100*total_acc/len(testloader.dataset):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
